{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64faaf45-8d7e-4d0e-bf7f-8e1c2eec1a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.build_sam import  *\n",
    "from segment_anything.automatic_mask_generator import SamAutomaticMaskGenerator\n",
    "from segment_img import *\n",
    "# from general_inference import convert\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ad24a8-eb49-4eb1-a3a4-d9047d71a631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 模型加载成功 ====================\n",
      "\n",
      "处理完成：COCO_train2014_000000098304_ann003007.jpg，耗时 20.43 秒\n",
      "处理完成：COCO_train2014_000000098304_ann099893.jpg，耗时 19.96 秒\n",
      "处理完成：COCO_train2014_000000098304_ann108703.jpg，耗时 19.99 秒\n",
      "处理完成：COCO_train2014_000000098304_ann115415.jpg，耗时 21.33 秒\n",
      "处理完成：COCO_train2014_000000098304_ann116865.jpg，耗时 19.74 秒\n",
      "处理完成：COCO_train2014_000000098304_ann120114.jpg，耗时 21.12 秒\n",
      "处理完成：COCO_train2014_000000098304_ann1490146.jpg，耗时 20.18 秒\n",
      "处理完成：COCO_train2014_000000098304_ann1511501.jpg，耗时 21.30 秒\n",
      "处理完成：COCO_train2014_000000098304_ann1513367.jpg，耗时 21.19 秒\n",
      "处理完成：COCO_train2014_000000098304_ann2099764.jpg，耗时 20.78 秒\n",
      "处理完成：COCO_train2014_000000098304_ann2222700.jpg，耗时 19.58 秒\n",
      "处理完成：COCO_train2014_000000098304_ann2222956.jpg，耗时 20.46 秒\n",
      "所有分割结果保存到：/root/data_preprocessing/box_labeled/test_data_sam/results.json\n"
     ]
    }
   ],
   "source": [
    "img_path = '/root/data_preprocessing/box_labeled/test_data_croped'\n",
    "checkpoint_path = '/root/autodl-fs/pretrain_UniLSeg/sam_vit_h_4b8939.pth'\n",
    "# checkpoint_l = '/Users/mtsbx/PycharmProjects/UniLSeg/data_preprocessing/segment-anything/pretrain/sam_vit_l_0b3195.pth'\n",
    "\n",
    "input_dir = img_path\n",
    "output_dir = '/root/data_preprocessing/box_labeled/test_data_sam'\n",
    "json_output_path = os.path.join(output_dir, \"results.json\")\n",
    "\n",
    "sam_model = build_sam_vit_h(checkpoint_path)\n",
    "mask_generator  = SamAutomaticMaskGenerator(sam_model)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# load_model\n",
    "sam_model = build_sam_vit_h(checkpoint_path)\n",
    "mask_generator = SamAutomaticMaskGenerator(sam_model)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 20 + \" 模型加载成功 \" + \"=\" * 20 + \"\\n\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# 遍历输入目录中所有图片文件\n",
    "for filename in os.listdir(input_dir):\n",
    "    i = 0\n",
    "    i += 1\n",
    "    if i > 1:\n",
    "        break\n",
    "    if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp')):\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        start_time = time.time()\n",
    "        # 读取图像（OpenCV 返回 BGR 格式）\n",
    "        img_bgr = cv2.imread(img_path)\n",
    "        if img_bgr is None:\n",
    "            print(f\"无法加载图像：{img_path}\")\n",
    "            continue\n",
    "        # 转换为 RGB 格式（SAM 模型一般使用 RGB 格式）\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 生成 mask，输入要求为 HWC, uint8 格式的 NumPy 数组\n",
    "        masks = mask_generator.generate(img_rgb)\n",
    "\n",
    "        # 保存每个 mask 的二值图像，同时记录数值信息\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        image_results = {\n",
    "            \"image\": filename,\n",
    "            \"masks\": []\n",
    "        }\n",
    "        for i, mask_info in enumerate(masks):\n",
    "            seg = mask_info[\"segmentation\"]\n",
    "            seg = ensure_mask_2d(seg)\n",
    "            # 将布尔型 mask 转换为 0-255 的 uint8 图像\n",
    "            seg_img = (seg.astype(np.uint8)) * 255\n",
    "            mask_filename = f\"{base_name}_mask_{i}.png\"\n",
    "            out_path = os.path.join(output_dir, mask_filename)\n",
    "            cv2.imwrite(out_path, seg_img)\n",
    "\n",
    "            # 保存该 mask 的数值信息\n",
    "            mask_data = {\n",
    "                \"mask_file\": mask_filename,\n",
    "                \"bbox\": mask_info[\"bbox\"],  # [x, y, w, h]\n",
    "                \"area\": mask_info[\"area\"],\n",
    "                \"predicted_iou\": mask_info[\"predicted_iou\"],\n",
    "                \"stability_score\": mask_info[\"stability_score\"],\n",
    "                \"point_coords\": mask_info[\"point_coords\"],\n",
    "                \"crop_box\": mask_info[\"crop_box\"]\n",
    "            }\n",
    "            image_results[\"masks\"].append(mask_data)\n",
    "\n",
    "        all_results.append(image_results)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"处理完成：{filename}，耗时 {elapsed_time:.2f} 秒\")\n",
    "\n",
    "# 将所有结果保存到 JSON 文件中\n",
    "with open(json_output_path, \"w\") as f:\n",
    "    json.dump(all_results, f, indent=4)\n",
    "print(f\"所有分割结果保存到：{json_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76ee331f-4f22-4be8-8b85-58c3e755f8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_overlay.jpg （59 masks）\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as maskUtils\n",
    "from segment_anything import build_sam_vit_h, SamAutomaticMaskGenerator\n",
    "\n",
    "def overlay_and_save_masks(\n",
    "    input_dir: str,\n",
    "    checker_json: str,\n",
    "    checkpoint_path: str,\n",
    "    output_dir: str,\n",
    "    alpha: float = 0.5,\n",
    "    max_images: int = None\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. 加载 SAM 模型\n",
    "    sam = build_sam_vit_h(checkpoint_path)\n",
    "    mask_gen = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "    # 2. 如果提供了 COCO JSON，则只处理其中的文件\n",
    "    valid_fnames = None\n",
    "    if checker_json:\n",
    "        coco = COCO(checker_json)\n",
    "        valid_fnames = {info['file_name'] for info in coco.loadImgs(coco.getImgIds())}\n",
    "\n",
    "    # 3. 遍历目录\n",
    "    for idx, fname in enumerate(sorted(os.listdir(input_dir))):\n",
    "        if max_images and idx >= max_images:\n",
    "            break\n",
    "        if not fname.lower().endswith(('.jpg','.png','jpeg','bmp')):\n",
    "            continue\n",
    "        if valid_fnames and fname not in valid_fnames:\n",
    "            continue\n",
    "\n",
    "        img_path = os.path.join(input_dir, fname)\n",
    "        img_bgr  = cv2.imread(img_path)\n",
    "        if img_bgr is None:\n",
    "            print(f\"[Warning] 无法加载 {img_path}\")\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 4. 生成掩码列表\n",
    "        masks = mask_gen.generate(img_rgb)\n",
    "\n",
    "        # 5. 叠加\n",
    "        overlay = img_rgb.copy()\n",
    "        for m in masks:\n",
    "            seg = m[\"segmentation\"]\n",
    "\n",
    "            # 如果是 RLE dict，先解码\n",
    "            if isinstance(seg, dict):\n",
    "                seg = maskUtils.decode(seg)  # returns HxW ndarray of {0,1}\n",
    "\n",
    "            # 如果多通道，把它 squeeze 到 2D\n",
    "            if isinstance(seg, np.ndarray) and seg.ndim > 2:\n",
    "                seg = np.squeeze(seg)\n",
    "\n",
    "            # seg 现在应该是 HxW 布尔/0-1 数组\n",
    "            mask_bool = seg.astype(bool)\n",
    "\n",
    "            # 随机颜色\n",
    "            color = [random.randint(0,255) for _ in range(3)]\n",
    "            # alpha 混合\n",
    "            overlay[mask_bool] = (\n",
    "                overlay[mask_bool] * (1 - alpha) +\n",
    "                np.array(color) * alpha\n",
    "            ).astype(np.uint8)\n",
    "\n",
    "        # 6. 转回 BGR 并保存\n",
    "        out_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)\n",
    "        save_name = f\"{os.path.splitext(fname)[0]}_overlay.jpg\"\n",
    "        save_path = os.path.join(output_dir, save_name)\n",
    "        cv2.imwrite(save_path, out_bgr)\n",
    "        print(f\"[Saved] {save_path} （{len(masks)} masks）\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # input_dir      = '/root/data_preprocessing/box_labeled/test_data_croped'\n",
    "    input_dir      = '/root/data_preprocessing/box_labeled/sam_test'\n",
    "    checker_json   = None   # 或者你的 'instances_filtered.json'\n",
    "    checkpoint     = '/root/autodl-fs/pretrain_UniLSeg/sam_vit_h_4b8939.pth'\n",
    "    # output_dir     = '/root/data_preprocessing/box_labeled/test_data_sam_overlay'\n",
    "    output_dir     = '/root/data_preprocessing/box_labeled/sam_test'\n",
    "    \n",
    "    overlay_and_save_masks(\n",
    "        input_dir=input_dir,\n",
    "        checker_json=checker_json,\n",
    "        checkpoint_path=checkpoint,\n",
    "        output_dir=output_dir,\n",
    "        alpha=0.5,\n",
    "        max_images=None  # 全部图片\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc750f2f-8d26-4daa-86fd-8784863e5ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_0.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_0.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_1.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_1.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_2.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_2.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_3.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_3.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_4.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_4.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_5.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_5.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_6.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_6.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_7.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_7.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_8.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_8.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_9.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_9.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_10.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_10.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_11.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_11.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_12.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_12.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_13.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_13.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_14.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_14.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_15.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_15.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_16.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_16.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_17.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_17.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_18.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_18.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_19.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_19.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_20.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_20.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_21.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_21.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_22.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_22.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_23.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_23.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_24.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_24.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_25.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_25.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_26.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_26.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_27.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_27.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_28.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_28.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_29.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_29.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_30.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_30.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_31.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_31.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_32.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_32.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_33.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_33.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_34.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_34.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_35.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_35.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_36.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_36.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_37.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_37.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_38.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_38.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_39.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_39.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_40.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_40.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_41.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_41.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_42.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_42.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_43.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_43.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_44.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_44.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_45.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_45.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_46.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_46.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_47.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_47.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_48.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_48.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_49.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_49.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_50.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_50.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_51.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_51.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_52.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_52.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_53.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_53.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_54.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_54.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_55.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_55.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_56.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_56.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_57.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_57.png\n",
      "[Saved] mask: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_mask_58.png\n",
      "[Saved] object crop: /root/data_preprocessing/box_labeled/sam_test/COCO_train2014_000000098304_ann116865_obj_58.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from segment_anything import build_sam_vit_h, SamAutomaticMaskGenerator\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "def segment_and_save(\n",
    "    img_path: str,\n",
    "    checkpoint_path: str,\n",
    "    output_dir: str,\n",
    "    model_type: str = \"vit_h\",  # \"vit_h\" 对应 checkpoint_h, 若用 vit_l 则加载相应权重\n",
    "    pick_largest: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    对单张图片做 SAM 分割，选取面积最大的 mask，保存：\n",
    "      - 原图同尺寸的二值掩码：mask.png\n",
    "      - 只含目标的 RGB 抠图：obj.png\n",
    "    \n",
    "    Args:\n",
    "        img_path:        待分割的图片路径\n",
    "        checkpoint_path: SAM 模型权重文件路径\n",
    "        output_dir:      输出目录，会自动创建\n",
    "        model_type:      \"vit_h\" 或 \"vit_l\"（名称要与你的 checkpoint 一致）\n",
    "        pick_largest:    是否只保留面积最大的一个 mask\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 1. 加载 SAM 与 mask generator\n",
    "    sam = build_sam_vit_h(checkpoint_path) if model_type==\"vit_h\" \\\n",
    "          else build_sam_vit_h(checkpoint_path, model_type=\"vit_l\")\n",
    "    mask_gen = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "    # 2. 读取图像并转 RGB\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    if img_bgr is None:\n",
    "        raise FileNotFoundError(f\"无法加载图片: {img_path}\")\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # 3. 调用 SAM 生成所有 mask\n",
    "    masks = mask_gen.generate(img_rgb)\n",
    "    if not masks:\n",
    "        print(\"⚠️ 未生成任何 mask，跳过。\")\n",
    "        return\n",
    "\n",
    "    # 4. 挑一个 mask：要么最大的，要么所有\n",
    "    if pick_largest:\n",
    "        mask_info = max(masks, key=lambda m: m[\"area\"])\n",
    "        mask_list = [mask_info[\"segmentation\"]]\n",
    "    else:\n",
    "        mask_list = [m[\"segmentation\"] for m in masks]\n",
    "\n",
    "    # 5. 处理并保存\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    for idx, seg in enumerate(mask_list):\n",
    "        # RLE 解码\n",
    "        if isinstance(seg, dict):\n",
    "            seg = maskUtils.decode(seg)\n",
    "        # squeeze 到 2D\n",
    "        if isinstance(seg, np.ndarray) and seg.ndim > 2:\n",
    "            seg = np.squeeze(seg)\n",
    "        mask_bool = seg.astype(bool)\n",
    "\n",
    "        # 保存二值掩码图\n",
    "        mask_img = (mask_bool.astype(np.uint8)) * 255\n",
    "        mask_path = os.path.join(output_dir, f\"{base}_mask_{idx}.png\")\n",
    "        cv2.imwrite(mask_path, mask_img)\n",
    "        print(f\"[Saved] mask: {mask_path}\")\n",
    "\n",
    "        # 抠图：只保留前景\n",
    "        obj_rgb = img_rgb.copy()\n",
    "        obj_rgb[~mask_bool] = 255  # 背景置白，方便查看\n",
    "        obj_bgr = cv2.cvtColor(obj_rgb, cv2.COLOR_RGB2BGR)\n",
    "        obj_path = os.path.join(output_dir, f\"{base}_obj_{idx}.png\")\n",
    "        cv2.imwrite(obj_path, obj_bgr)\n",
    "        print(f\"[Saved] object crop: {obj_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # —— 用户配置 —— \n",
    "    input_image     = \"/root/data_preprocessing/box_labeled/test_data_croped/COCO_train2014_000000098304_ann116865.jpg\"\n",
    "    sam_checkpoint  = \"/root/autodl-fs/pretrain_UniLSeg/sam_vit_h_4b8939.pth\"\n",
    "    output_folder   = \"/root/data_preprocessing/box_labeled/sam_test\"\n",
    "    model_variant   = \"vit_h\"   # 或者 \"vit_l\"（若你下载了 ViT-L checkpoint）\n",
    "\n",
    "    segment_and_save(\n",
    "        img_path=input_image,\n",
    "        checkpoint_path=sam_checkpoint,\n",
    "        output_dir=output_folder,\n",
    "        model_type=model_variant,\n",
    "        pick_largest=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98341c67-88f0-48ec-b640-b62cf92de892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
